{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.dom import minidom\n",
    "import re\n",
    "def prettify(rough_string):\n",
    "    reparsed = minidom.parseString(rough_string)\n",
    "    pretty = re.sub(r\"[\\t ]+\\n\", \"\", reparsed.toprettyxml(indent=\"\\t\"))  # インデント後の不要な改行を削除\n",
    "    pretty = pretty.replace(\">\\n\\n\\t<\", \">\\n\\t<\")  # 不要な空行を削除\n",
    "    pretty = re.sub(r\"\\n\\s*\\n\", \"\\n\", pretty)  # 連続した改行（空白行を含む）を単一の改行に置換\n",
    "    return pretty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [01:16<00:00,  1.42s/it]\n"
     ]
    }
   ],
   "source": [
    "def fix_pb(soup):\n",
    "    pbs = soup.find_all(\"pb\")\n",
    "\n",
    "    for pb in pbs:\n",
    "        zone_id = pb.get(\"facs\").split(\"#\")[1]\n",
    "\n",
    "        zone = soup.find(\"zone\", {\"xml:id\": zone_id})\n",
    "\n",
    "        url = zone.parent.find(\"graphic\").get(\"url\")\n",
    "\n",
    "        x = zone.get(\"ulx\")\n",
    "        y = zone.get(\"uly\")\n",
    "\n",
    "        w = int(zone.get(\"lrx\")) - int(x)\n",
    "        h = int(zone.get(\"lry\")) - int(y)\n",
    "\n",
    "        url_part = url.replace(\"/full/full/\", f\"/{x},{y},{w},{h}/full/\")\n",
    "\n",
    "        pb[\"facs\"] = url_part\n",
    "\n",
    "        pb[\"corresp\"] = f\"#{zone_id}\"\n",
    "\n",
    "def fix_facs(soup):\n",
    "    surfaceGrp = soup.find(\"surfaceGrp\")\n",
    "\n",
    "    facsimile = soup.find(\"facsimile\")\n",
    "\n",
    "    facsimile[\"sameAs\"] = surfaceGrp[\"facs\"]\n",
    "\n",
    "    for surface, idx in zip(surfaceGrp.find_all(\"surface\"), range(len(surfaceGrp.find_all(\"surface\")))):\n",
    "        surface_new = soup.new_tag(\"surface\")\n",
    "\n",
    "        graphic = surface.find(\"graphic\")\n",
    "\n",
    "        info_url = graphic[\"url\"].split(\"/full/full/\")[0] + \"/info.json\"\n",
    "\n",
    "        info = requests.get(info_url).json()\n",
    "\n",
    "        surface_new[\"xml:id\"] = f\"f{str(idx+1).zfill(3)}\"\n",
    "\n",
    "        surface_new[\"ulx\"] = str(0)\n",
    "        surface_new[\"uly\"] = str(0)\n",
    "\n",
    "        surface_new[\"lrx\"] = str(info[\"width\"])\n",
    "        surface_new[\"lry\"] = str(info[\"height\"])\n",
    "\n",
    "        surface_new[\"sameAs\"] = graphic[\"n\"]\n",
    "\n",
    "        graphic_new = soup.new_tag(\"graphic\")\n",
    "\n",
    "        graphic_new[\"width\"] = str(info[\"width\"]) + \"px\"\n",
    "        graphic_new[\"height\"] = str(info[\"height\"]) + \"px\"\n",
    "\n",
    "        graphic_new[\"url\"] = graphic[\"url\"]\n",
    "\n",
    "        graphic_new[\"sameAs\"] = graphic[\"url\"].split(\"/full/full/\")[0]\n",
    "\n",
    "\n",
    "        # label = soup.new_tag(\"label\")\n",
    "        # label.string = str(idx+1)\n",
    "\n",
    "        # surface_new.append(label)\n",
    "\n",
    "        surface_new.append(graphic_new)\n",
    "\n",
    "        for zone in surface.find_all(\"zone\"):\n",
    "            surface_new.append(zone)\n",
    "\n",
    "        facsimile.append(surface_new)\n",
    "\n",
    "    surfaceGrp.decompose()\n",
    "\n",
    "def add_revision(soup):\n",
    "    revisionDesc = soup.new_tag(\"revisionDesc\", status=\"published\")\n",
    "\n",
    "    soup.find(\"teiHeader\").append(revisionDesc)\n",
    "\n",
    "    change = soup.new_tag(\"change\", when=\"2024-06-28\", who=\"#snakamura\")\n",
    "    revisionDesc.append(change)\n",
    "\n",
    "    change.string = \"pb要素のfacs属性を修正しました。facsimile要素を修正しました。\"\n",
    "\n",
    "def fix_resp(soup):\n",
    "    respStmts = soup.find_all(\"respStmt\")\n",
    "\n",
    "    for respStmt in respStmts:\n",
    "\n",
    "        if \"Satoru Nakamura\" in respStmt.text:\n",
    "            respStmt[\"xml:id\"] = \"snakamura\"\n",
    "\n",
    "files = glob.glob(\"../../tei/*.xml\")\n",
    "\n",
    "files.sort()\n",
    "\n",
    "for file in tqdm(files):\n",
    "\n",
    "    opath = \"../../xml/lw/\" + file.split(\"/\")[-1]\n",
    "\n",
    "    # print(file)\n",
    "    with open(file, 'r') as f:\n",
    "        text = f.read()\n",
    "\n",
    "        text = '''<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<?xml-model href=\"https://kouigenjimonogatari.github.io/lw/tei_genji.rng\" type=\"application/xml\" schematypens=\"http://relaxng.org/ns/structure/1.0\"?>\n",
    "<?xml-stylesheet type=\"text/css\" href=\"https://kouigenjimonogatari.github.io/lw/tei_genji.css\"?>\n",
    "''' + text\n",
    "        \n",
    "        soup = BeautifulSoup(text, \"xml\")\n",
    "\n",
    "        fix_pb(soup)\n",
    "\n",
    "        fix_facs(soup)\n",
    "\n",
    "        add_revision(soup)\n",
    "\n",
    "        fix_resp(soup)\n",
    "\n",
    "    with open(opath, 'w') as f:\n",
    "        f.write(prettify(str(soup)))\n",
    "\n",
    "    # break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
